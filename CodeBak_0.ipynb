{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PaddlePaddle 1.7.2 (Python 3.5)",
      "language": "python",
      "name": "py35-paddle1.2.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "408093.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsteriskAzurain/illuminera/blob/main/CodeBak_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FOSwB-1KCYh"
      },
      "source": [
        "Copy from [Baidu AI Studio](https://aistudio.baidu.com/aistudio/projectdetail/408093)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Mk7sEma2JFpe"
      },
      "source": [
        "\n",
        "\n",
        "### [Dataset Introduction](https://keras.io/datasets/)\n",
        "\n",
        "Dataset of 11,228 newswires from Reuters, labeled over 46 topics. As with the IMDB dataset, each wire is encoded as a sequence of word indexes (same conventions).\n",
        "\n",
        "**Usage:**\n",
        "\n",
        "```python\n",
        "from keras.datasets import reuters\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
        "                                                         num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=113,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)\n",
        "```\n",
        "\n",
        "The specifications are the same as that of the IMDB dataset, with the addition of:\n",
        "\n",
        "- **test_split**: float. Fraction of the dataset to be used as test data.\n",
        "\n",
        "This dataset also makes available the word index used for encoding the sequences:\n",
        "\n",
        "```\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "```\n",
        "\n",
        "- **Returns:** A dictionary where key are words (str) and values are indexes (integer). eg. `word_index[\"giraffe\"]` might return `1234`.\n",
        "- **Arguments:**\n",
        "  - **path**: if you do not have the index file locally (at `'~/.keras/datasets/' + path`), it will be downloaded to this location.\n",
        "\n",
        "  - **Returns:**\n",
        "  - 2 tuples:\n",
        "    - **x_train, x_test**: list of sequences, which are lists of indexes (integers). If the num_words argument was specific, the maximum possible index value is num_words-1. If the maxlen argument was specified, the largest possible sequence length is maxlen.\n",
        "    - **y_train, y_test**: list of integer labels (1 or 0).\n",
        "- **Arguments:**\n",
        "  - **path**: if you do not have the data locally (at `'~/.keras/datasets/' + path`), it will be downloaded to this location.\n",
        "  - **num_words**: integer or None. Top most frequent words to consider. Any less frequent word will appear as `oov_char` value in the sequence data.\n",
        "  - **skip_top**: integer. Top most frequent words to ignore (they will appear as `oov_char` value in the sequence data).\n",
        "  - **maxlen**: int. Maximum sequence length. Any longer sequence will be truncated.\n",
        "  - **seed**: int. Seed for reproducible data shuffling.\n",
        "  - **start_char**: int. The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.\n",
        "  - **oov_char**: int. words that were cut out because of the `num_words` or `skip_top` limit will be replaced with this character.\n",
        "  - **index_from**: int. Index actual words with this index and higher.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_uKbulaJFpf"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Ay25FSi8JFpi"
      },
      "source": [
        "### Tensorflow 2.0 initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5B5redGJFpj"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yddge589JFpl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Sequential\n",
        "\n",
        "import datetime, os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "bN2X7VftJFpo"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQRXn5tPJFpp"
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = 'logs/' + current_time\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYqjNq8eJFps"
      },
      "source": [
        "%tensorboard --logdir logs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "FcRwS7-pJFpu"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVspW4wcJFpv"
      },
      "source": [
        "num_epochs = 200\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "\n",
        "num_classes = 46"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcSHnI_mJFpy"
      },
      "source": [
        "total_words = 40000\n",
        "max_news_words = 400\n",
        "embedding_len = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SA0Lmz-JFp1"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = keras.datasets.reuters.load_data(num_words = total_words)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI-6NDM3JFp3"
      },
      "source": [
        "## pad sequence to the same length\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen = max_news_words)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen = max_news_words)\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOfdFhdEJFp8"
      },
      "source": [
        "len(x_test[51])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6WKS63XJFp_"
      },
      "source": [
        "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUE-MFZjJFqB"
      },
      "source": [
        "res = next(iter(ds_train))\n",
        "res[0].shape, res[1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3NtVPuRJFqE"
      },
      "source": [
        "def preprocess(x,y):\n",
        "  y = tf.one_hot(y, depth=num_classes)\n",
        "  return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ifbETbJFqH"
      },
      "source": [
        "# shuffle and batch dataset and drop the last batch shorter than batch_size\n",
        "ds_train = ds_train.shuffle(1000).map(preprocess).batch(batch_size, drop_remainder = True)\n",
        "ds_test = ds_test.shuffle(1000).map(preprocess).batch(batch_size, drop_remainder = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7KPc6xuEJFqK"
      },
      "source": [
        "### RNN Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "SCT3QxAAJFqK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "x0gdAvmdJFqK"
      },
      "source": [
        "#### SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CYf_DxeJFqL"
      },
      "source": [
        "class RNN(keras.Model):\n",
        "  def __init__(self, num_units, num_classes):\n",
        "    super().__init__()\n",
        "    # embedding [b, 200] -> [b, 200, 100]\n",
        "    self.embedding = layers.Embedding(total_words, embedding_len, input_length=max_news_words)\n",
        "\n",
        "    self.RNN1 = layers.SimpleRNN(num_units, dropout = 0.5, return_sequences = True)\n",
        "    self.RNN2 = layers.SimpleRNN(num_units, dropout = 0.5, return_sequences = False)\n",
        "\n",
        "    self.fc = layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, inputs, training = None):\n",
        "    \n",
        "    outputs = self.embedding(inputs)\n",
        "    \n",
        "    outputs = self.RNN1(outputs, training = training)\n",
        "    outputs = self.RNN2(outputs, training = training)\n",
        "    outputs = self.fc(outputs)\n",
        "\n",
        "    return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "NoNkb3hCJFqN"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi-GEGTrJFqO"
      },
      "source": [
        "class LSTM(keras.Model):\n",
        "  def __init__(self, num_units, num_classes):\n",
        "    super().__init__()\n",
        "    # embedding [b, 200] -> [b, 200, 100]\n",
        "    self.embedding = layers.Embedding(total_words, embedding_len, input_length=max_news_words)\n",
        "\n",
        "    self.RNN1 = layers.LSTM(num_units, dropout = 0.5, return_sequences = True)\n",
        "    self.RNN2 = layers.LSTM(num_units, dropout = 0.5, return_sequences = False)\n",
        "\n",
        "    self.fc = layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, inputs, training = None):\n",
        "    \n",
        "    outputs = self.embedding(inputs)\n",
        "    \n",
        "    outputs = self.RNN1(outputs, training = training)\n",
        "    outputs = self.RNN2(outputs, training = training)\n",
        "    outputs = self.fc(outputs)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "bqgh8x9fJFqQ"
      },
      "source": [
        "#### GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T_LLVQ1JFqR"
      },
      "source": [
        "class GRU(keras.Model):\n",
        "  def __init__(self, num_units, num_classes):\n",
        "    super().__init__()\n",
        "    # embedding [b, 200] -> [b, 200, 100]\n",
        "    self.embedding = layers.Embedding(total_words, embedding_len, input_length=max_news_words)\n",
        "\n",
        "    self.RNN1 = layers.GRU(num_units, dropout = 0.5, return_sequences = True)\n",
        "    self.RNN2 = layers.GRU(num_units, dropout = 0.5, return_sequences = True)\n",
        "    self.RNN3 = layers.GRU(num_units, dropout = 0.5, return_sequences = False)\n",
        "\n",
        "    self.fc = layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, inputs, training = None):\n",
        "    \n",
        "    outputs = self.embedding(inputs)\n",
        "    \n",
        "    outputs = self.RNN1(outputs, training = training)\n",
        "    outputs = self.RNN2(outputs, training = training)\n",
        "    outputs = self.RNN3(outputs, training = training)\n",
        "    outputs = self.fc(outputs)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Oy_uHlG7JFqT"
      },
      "source": [
        "#### Keras Quick Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flwMqNzWJFqU"
      },
      "source": [
        "model = GRU(64,46)\n",
        "model.build(input_shape=(None, max_news_words))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
        "              loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics = ['accuracy'])\n",
        "history = model.fit(ds_train, epochs=100, validation_data=ds_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nyJaRCjpJFqY"
      },
      "source": [
        "#### TF2.0 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfhxR4LXJFqY"
      },
      "source": [
        "model = GRU(64,46)\n",
        "model.build(input_shape=(None, max_news_words))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "eSKYf-PWJFqa"
      },
      "source": [
        "#### Initialize the optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT5ZOZXOJFqb"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate= learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yIVYFDtaJFqd"
      },
      "source": [
        "#### Train Evaluate and log the model in tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn9k-3XeJFqd"
      },
      "source": [
        "categorical_accuracy_train = keras.metrics.CategoricalAccuracy()\n",
        "categorical_accuracy_test = keras.metrics.CategoricalAccuracy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg3b8yiKJFqf"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for step, (x, y) in enumerate(ds_train):\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(x, training = True)\n",
        "      loss = tf.keras.losses.categorical_crossentropy(y_true=y, y_pred=logits, from_logits = True)\n",
        "      loss = tf.reduce_mean(loss)  \n",
        "    \n",
        "    grad = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars= zip(grad, model.trainable_variables))\n",
        "\n",
        "    [x_train, y_train] = next(iter(ds_train))\n",
        "    train_logits = model(x_train, training = False)\n",
        "    categorical_accuracy_train.update_state(y_true = y_train, y_pred=train_logits)\n",
        "    train_accuracy = categorical_accuracy_train.result().numpy()\n",
        "    \n",
        "    [x_test, y_test] = next(iter(ds_test))\n",
        "    logits = model(x_test, training = False)\n",
        "    categorical_accuracy_test.update_state(y_true = y_test, y_pred=logits)\n",
        "    accuracy = categorical_accuracy_test.result().numpy()\n",
        "\n",
        "    if step%20 == 0:\n",
        "      print(\"epoch: {}, step: {}, loss: {}, train_accuracy: {} test_accuracy: {}\".format(epoch, step, loss.numpy(),train_accuracy,accuracy))\n",
        "\n",
        "      # with summary_writer.as_default():\n",
        "      #   tf.summary.scalar(\"loss epoch: \"+str(epoch), loss.numpy(), step = step)\n",
        "      #   tf.summary.scalar(\"test_acc epoch: \"+str(epoch), accuracy, step = step)\n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar(\"epoch_loss\", loss.numpy(), step=epoch)\n",
        "    tf.summary.scalar(\"epoch_train_acc\",train_accuracy, step=epoch)\n",
        "    tf.summary.scalar(\"epoch_test_acc\", accuracy, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek_F6d3EJFqh",
        "outputId": "a17c6514-7894-4c18-9b57-4fc9dd4366a0"
      },
      "source": [
        "import pandas as pd\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "! pip install xlrd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
            "Collecting xlrd\n",
            "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.4MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: xlrd\n",
            "Successfully installed xlrd-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR81gAORJFqm"
      },
      "source": [
        "myfile='data/信息.xlsx'\r\n",
        "pwd=os.getcwd()\r\n",
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foFweediJFqo"
      },
      "source": [
        "data=pd.read_excel(io=myfile,header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go5QNJCJJFqq",
        "outputId": "1bd1563f-1d22-4468-b7e2-14693c1818f1"
      },
      "source": [
        "data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StaffName_Chinese</th>\n",
              "      <th>StaffName_English</th>\n",
              "      <th>E_Name</th>\n",
              "      <th>AD_Account</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>陈彦慧</td>\n",
              "      <td>Lynn Chen</td>\n",
              "      <td>Lynn Chen</td>\n",
              "      <td>Lynn.Chen</td>\n",
              "      <td>Lynn.Chen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>周娉</td>\n",
              "      <td>Evan Zhou</td>\n",
              "      <td>Evan Zhou</td>\n",
              "      <td>Evan.Zhou</td>\n",
              "      <td>Evan.Zhou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>蔡奕</td>\n",
              "      <td>Carol Cai</td>\n",
              "      <td>Carol Cai</td>\n",
              "      <td>Carol.Cai</td>\n",
              "      <td>Carol.Cai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>董巍</td>\n",
              "      <td>David Dong</td>\n",
              "      <td>David Dong</td>\n",
              "      <td>David.Dong</td>\n",
              "      <td>David.Dong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>周波</td>\n",
              "      <td>Paul Zhou</td>\n",
              "      <td>Paul Zhou</td>\n",
              "      <td>Paul.Zhou</td>\n",
              "      <td>Paul.Zhou</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  StaffName_Chinese StaffName_English      E_Name  AD_Account        Code\n",
              "0               陈彦慧         Lynn Chen   Lynn Chen   Lynn.Chen   Lynn.Chen\n",
              "1                周娉         Evan Zhou   Evan Zhou   Evan.Zhou   Evan.Zhou\n",
              "2                蔡奕         Carol Cai   Carol Cai   Carol.Cai   Carol.Cai\n",
              "3                董巍        David Dong  David Dong  David.Dong  David.Dong\n",
              "4                周波         Paul Zhou   Paul Zhou   Paul.Zhou   Paul.Zhou"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IU5FWyOJFqs",
        "outputId": "af3edb67-faa0-4fa6-9140-242183baf77c"
      },
      "source": [
        "data.columns.values\r\n",
        "#data['Unnamed: 5'][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['StaffName_Chinese', 'StaffName_English', 'E_Name', 'AD_Account',\n",
              "       'Code'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8N8AKqbJFqu"
      },
      "source": [
        "for i in range(len(data)):\r\n",
        "    userid=data['id'][i]\r\n",
        "    oldID=data['PositionID'][i]\r\n",
        "    value=data['Unnamed: 5'][i]\r\n",
        "    newID=0 if str(value)=='nan' else int(value)\r\n",
        "    # print(userid,oldID,newID)\r\n",
        "    sql_str=\"update t_User_UserInfo set PositionID={1} where ID={0}\".format(userid,oldID)\r\n",
        "    print(sql_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rIU6bznJFqx"
      },
      "source": [
        "idarr=[]\r\n",
        "for i in range(len(data)):\r\n",
        "    userid=str(data['id'][i])\r\n",
        "    idarr.append(userid)\r\n",
        "idstr=','.join(idarr)\r\n",
        "print(idstr)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMcV_pQQJFq0"
      },
      "source": [
        "import pymssql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1xG9m3WJFq2"
      },
      "source": [
        "# server    数据库服务器名称或IP\r\n",
        "# user      用户名\r\n",
        "# password  密码\r\n",
        "# database  数据库名称\r\n",
        "server='192.168.1.245'\r\n",
        "user='sa'\r\n",
        "password='Illuminera2011'\r\n",
        "database='IllumineraERP'\r\n",
        "conn = pymssql.connect(server, user, password, database)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya6dwXlEJFq4"
      },
      "source": [
        "cursor = conn.cursor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzty46HtJFq6"
      },
      "source": [
        "# myfile='data/mentee.xlsx'\r\n",
        "myfile='data/pydata.xlsx'\r\n",
        "staffinfo_file='data/staffinfo.xlsx'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I9sTyoHJFq9",
        "outputId": "365de94a-1ed8-4a0e-e8ac-646244fcf642"
      },
      "source": [
        "staff_dict={}\r\n",
        "staff_data=pd.read_excel(io=staffinfo_file,header=0)\r\n",
        "print(staff_data.columns.values)\r\n",
        "\r\n",
        "for i in range(len(staff_data)):\r\n",
        "    pk=int(staff_data['HR_StaffInfoID'][i])\r\n",
        "    name=str(staff_data['StaffName_English'][i]).strip()\r\n",
        "    staff_dict.update({name:pk})\r\n",
        "len(staff_dict)\r\n",
        "print(staff_dict['Aaron Guo'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HR_StaffInfoID' 'StaffName_English']\n",
            "72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_LqORAgJFq_",
        "outputId": "8d440dc6-2159-4564-9af1-e05e9bfa386f"
      },
      "source": [
        "data=pd.read_excel(io=myfile,header=0)\r\n",
        "data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-649de3075199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6zf6Z3nJFrB",
        "outputId": "b9647856-e639-4143-fb64-cfab5d00ce12"
      },
      "source": [
        "data.columns.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mentorname', 'HR_StaffInfoID', 'menteename', 'MenteeID',\n",
              "       'StartDate', 'IsDeleted', 'CreateDate', 'CreateUserID',\n",
              "       'CurrentStatus'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBU2dq7WJFrD"
      },
      "source": [
        "sql5=\"select m.HR_MenteeID from t_HR_Mentee m left join t_HR_StaffInfo s1 on m.HR_StaffInfoID=s1.HR_StaffInfoID left join t_HR_StaffInfo s2 on m.MenteeID=s2.HR_StaffInfoID\"\r\n",
        "sql4=sql5+\" where s1.StaffName_English='{}' and s2.StaffName_English='{}'\"\r\n",
        "menteelist=[]\r\n",
        "flist2=[]\r\n",
        "for i in range(len(data)):\r\n",
        "    m1=data['Mentor Name'][i]\r\n",
        "    m2=data['MenteeName'][i]\r\n",
        "    menteelist.append(m2)\r\n",
        "    s=sql4.format(m1,m2)\r\n",
        "    flist2.append(s)\r\n",
        "for ss in flist2:\r\n",
        "    print(ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CcT740yOJFrF"
      },
      "source": [
        "sql temp\n",
        "```SQL\n",
        "select \n",
        "\tm.HR_MenteeID ,\n",
        "\tm.HR_StaffInfoID as 'mentor ID', \n",
        "\ts1.StaffName_English as 'Mentor Name',\n",
        "\ts1.StaffName_Chinese as 'Mentor C_Name', \n",
        "\tm.MenteeID as 'Mentee ID', \n",
        "\ts2.StaffName_English as 'Mentee Name',\n",
        "\ts2.StaffName_Chinese as 'Mentee C_Name',\n",
        "\tm.StartDate, m.EndDate, m.CurrentStatus\n",
        "from t_HR_Mentee m\n",
        "\tleft join t_HR_StaffInfo s1 on m.HR_StaffInfoID=s1.HR_StaffInfoID\n",
        "\tleft join t_HR_StaffInfo s2 on m.MenteeID=s2.HR_StaffInfoID\n",
        "where m.IsDeleted=1 and m.CurrentStatus=1\n",
        "ORDER BY\n",
        "\t(\n",
        "\t\tCASE s2.StaffName_English\n",
        "\t\tWHEN '高' THEN 3\n",
        "\t\tWHEN '中' THEN 2\n",
        "\t\tELSE 123\n",
        "\t\tEND\n",
        "\t) ASC\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-LZ52NAWJFrG",
        "outputId": "31451e7a-451d-4b5a-d8de-6909c193fd16"
      },
      "source": [
        "sql1=\"\"\"\r\n",
        "select \r\n",
        "\tm.HR_MenteeID ,\r\n",
        "\ts1.StaffName_English as 'Mentor Name',\r\n",
        "\ts2.StaffName_English as 'Mentee Name',\r\n",
        "\tm.StartDate, m.EndDate\r\n",
        "from t_HR_Mentee m\r\n",
        "\tleft join t_HR_StaffInfo s1 on m.HR_StaffInfoID=s1.HR_StaffInfoID\r\n",
        "\tleft join t_HR_StaffInfo s2 on m.MenteeID=s2.HR_StaffInfoID \r\n",
        "\"\"\"\r\n",
        "sql2=\"where s2.StaffName_English = '{}'\"\r\n",
        "sql3=\"WHEN '{}' THEN {}\"\r\n",
        "flist=[]\r\n",
        "i=1\r\n",
        "for m in menteelist:\r\n",
        "    # newstr=sql2.format(m)\r\n",
        "    newstr=sql3.format(m,i)\r\n",
        "    i+=1\r\n",
        "    flist.append(newstr)\r\n",
        "# len(flist)\r\n",
        "# print(sql1+' and '.join(flist))\r\n",
        "# print(sql1)\r\n",
        "for sql in flist:\r\n",
        "    print(sql)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WHEN 'Karen Duan' THEN 1\n",
            "WHEN 'Stella Yang' THEN 2\n",
            "WHEN 'Arlene Xu' THEN 3\n",
            "WHEN 'M LU' THEN 4\n",
            "WHEN 'Yulin Fei' THEN 5\n",
            "WHEN 'Ariel Chen' THEN 6\n",
            "WHEN 'Rose Feng' THEN 7\n",
            "WHEN 'Collin Zeng' THEN 8\n",
            "WHEN 'Chuting Chang' THEN 9\n",
            "WHEN 'Yang Yang' THEN 10\n",
            "WHEN 'Xue Wu' THEN 11\n",
            "WHEN 'Monica Yang' THEN 12\n",
            "WHEN 'Lily Chen' THEN 13\n",
            "WHEN 'Christina Liao' THEN 14\n",
            "WHEN 'Tong Wang' THEN 15\n",
            "WHEN 'Perry Bian' THEN 16\n",
            "WHEN 'Sifan Huai' THEN 17\n",
            "WHEN 'Joy Pu' THEN 18\n",
            "WHEN 'Sophia Zhuo' THEN 19\n",
            "WHEN 'Yuki Wu' THEN 20\n",
            "WHEN 'Daisy Zhu' THEN 21\n",
            "WHEN 'Dorothy Zhu' THEN 22\n",
            "WHEN 'Olivia Ma' THEN 23\n",
            "WHEN 'Haofu Li' THEN 24\n",
            "WHEN 'Patrick Li' THEN 25\n",
            "WHEN 'Aaron Guo' THEN 26\n",
            "WHEN 'Lynn Zheng' THEN 27\n",
            "WHEN 'Claire Li' THEN 28\n",
            "WHEN 'Eric Duan' THEN 29\n",
            "WHEN 'Erin Tang' THEN 30\n",
            "WHEN 'Shelly Wei' THEN 31\n",
            "WHEN 'Angie Shen' THEN 32\n",
            "WHEN 'Viona Li' THEN 33\n",
            "WHEN 'Ariel Zhang' THEN 34\n",
            "WHEN 'Shen Jing' THEN 35\n",
            "WHEN 'Denise Wu' THEN 36\n",
            "WHEN 'Tina Du' THEN 37\n",
            "WHEN 'Calvin Hu' THEN 38\n",
            "WHEN 'Zora Yu' THEN 39\n",
            "WHEN 'Sharon Shen' THEN 40\n",
            "WHEN 'Vera Xu' THEN 41\n",
            "WHEN 'Gabrielle Guan' THEN 42\n",
            "WHEN 'Theresa Ye' THEN 43\n",
            "WHEN 'Jerry Jiao' THEN 44\n",
            "WHEN 'Oorain Ju' THEN 45\n",
            "WHEN 'Janice Wang' THEN 46\n",
            "WHEN 'Vivi Wu' THEN 47\n",
            "WHEN 'Eveline Tan' THEN 48\n",
            "WHEN 'Wei Liu' THEN 49\n",
            "WHEN 'Sabrina Zhu' THEN 50\n",
            "WHEN 'Nora Xu' THEN 51\n",
            "WHEN 'Wendy Zang' THEN 52\n",
            "WHEN 'Sally Li' THEN 53\n",
            "WHEN 'Pencil Chen' THEN 54\n",
            "WHEN 'Sherry Yuan' THEN 55\n",
            "WHEN 'Pencil Chen' THEN 56\n",
            "WHEN 'Serlin Qian' THEN 57\n",
            "WHEN 'Skye Sun' THEN 58\n",
            "WHEN 'Neo Wu' THEN 59\n",
            "WHEN 'Zemin Fan' THEN 60\n",
            "WHEN 'Thea Cui' THEN 61\n",
            "WHEN 'Francis Huang' THEN 62\n",
            "WHEN 'Leo Li' THEN 63\n",
            "WHEN 'Tracy Kong' THEN 64\n",
            "WHEN 'Steven Shuai' THEN 65\n",
            "WHEN 'Flora Han' THEN 66\n",
            "WHEN 'Hui Wang' THEN 67\n",
            "WHEN 'Nerissa Sun' THEN 68\n",
            "WHEN 'Cyssi Chen' THEN 69\n",
            "WHEN 'Alex Li' THEN 70\n",
            "WHEN 'Shawn Song' THEN 71\n",
            "WHEN 'Robin Lin' THEN 72\n",
            "WHEN 'Mia Wei' THEN 73\n",
            "WHEN 'David Dong' THEN 74\n",
            "WHEN 'Shanshan Ye' THEN 75\n",
            "WHEN 'Frances Zhang' THEN 76\n",
            "WHEN 'Lily Wang' THEN 77\n",
            "WHEN 'Thea Zhang' THEN 78\n",
            "WHEN 'Lilith Hua' THEN 79\n",
            "WHEN 'Iris Xu' THEN 80\n",
            "WHEN 'Naomi Chen' THEN 81\n",
            "WHEN 'Xi Wen' THEN 82\n",
            "WHEN 'Jason Pan' THEN 83\n",
            "WHEN 'Vera Li' THEN 84\n",
            "WHEN 'Chang Su' THEN 85\n",
            "WHEN 'Jiajia Hao' THEN 86\n",
            "WHEN 'Fistan Jin' THEN 87\n",
            "WHEN 'Neal Teng' THEN 88\n",
            "WHEN 'Zenki Zhang' THEN 89\n",
            "WHEN 'Serena Zhang' THEN 90\n",
            "WHEN 'Duo Xu' THEN 91\n",
            "WHEN 'Chelsie Chen' THEN 92\n",
            "WHEN 'Issac Ku' THEN 93\n",
            "WHEN 'Evelyn Chen' THEN 94\n",
            "WHEN 'Jiayi Zhou' THEN 95\n",
            "WHEN 'Leon Duan' THEN 96\n",
            "WHEN 'Alice He' THEN 97\n",
            "WHEN 'July Lin' THEN 98\n",
            "WHEN 'Evan Zhou' THEN 99\n",
            "WHEN 'Lynn Chen' THEN 100\n",
            "WHEN 'Grace Chen' THEN 101\n",
            "WHEN 'Adele Wu' THEN 102\n",
            "WHEN 'Jenny Zhang' THEN 103\n",
            "WHEN 'Faye Tang' THEN 104\n",
            "WHEN 'Kevin Cai' THEN 105\n",
            "WHEN 'Carol Cai' THEN 106\n",
            "WHEN 'Kaya Zhang' THEN 107\n",
            "WHEN 'Clara Jia' THEN 108\n",
            "WHEN 'Matthew Lu' THEN 109\n",
            "WHEN 'Claire Zhang' THEN 110\n",
            "WHEN 'Karen Liu' THEN 111\n",
            "WHEN 'Jessie Sun' THEN 112\n",
            "WHEN 'Cindy Liu' THEN 113\n",
            "WHEN 'Mavis Tong' THEN 114\n",
            "WHEN 'Lace Zhang' THEN 115\n",
            "WHEN 'SETHI ASHOK' THEN 116\n",
            "WHEN 'Rebecca Zhou' THEN 117\n",
            "WHEN 'Leslie Wang' THEN 118\n",
            "WHEN 'Banban Wang' THEN 119\n",
            "WHEN 'Jane Zhang' THEN 120\n",
            "WHEN 'Eugene Yang' THEN 121\n",
            "WHEN 'Kang Su' THEN 122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a41IOeP6JFrK",
        "outputId": "4beeedd7-21fe-4563-89c8-121cede91407"
      },
      "source": [
        "mydict={}\r\n",
        "for i in range(len(data)):\r\n",
        "    m1=str(data['Mentor Name'][i]).strip()\r\n",
        "    old1=str(data['old mentor'][i]).strip()\r\n",
        "    # m2=data['MenteeName'][i]\r\n",
        "    # nm2=data['new mentee'][i]\r\n",
        "    # flag=True if(m1=='nan' or nm1=='nan' or str(m2)=='nan' or str(nm2)=='nan') else False\r\n",
        "    # if (str(m1)!='nan' and str(nm1)!='nan' and m1 != nm1):\r\n",
        "    if(str(old1)!='nan' and m1!=old1):\r\n",
        "        pk=int(data['pk'][i])\r\n",
        "        mydict.update({i+3:pk})\r\n",
        "mydict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 115, 28: 140, 29: 101, 37: 144, 40: 141, 41: 77, 46: 27, 56: 105}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnKbAB89JFrM",
        "outputId": "f88999a0-9d8f-4ae1-928b-b602058b6816"
      },
      "source": [
        "for k,v in mydict.items():\r\n",
        "    print(\"line:{}, pk:{}\".format(k,v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "line:10, pk:115\n",
            "line:28, pk:140\n",
            "line:29, pk:101\n",
            "line:37, pk:144\n",
            "line:40, pk:141\n",
            "line:41, pk:77\n",
            "line:46, pk:27\n",
            "line:56, pk:105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-lxFkooJFrO",
        "outputId": "58f70b9d-f199-4f46-9046-92314d28964a"
      },
      "source": [
        "m1=str(data['Mentor Name'][8]).strip()\r\n",
        "nm1=str(data['new mentor'][8]).strip()\r\n",
        "m1 == nm1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3HzdpovJFrR",
        "outputId": "8667c9f2-06af-4ec4-f55a-6a6624b73e76"
      },
      "source": [
        "filename=open('data/ssby.txt','r',encoding='utf-8')\r\n",
        "filename"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='data/ssby.txt' mode='r' encoding='utf-8'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MQ6nBqQJFrU"
      },
      "source": [
        "filename.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OBP7xavJFrY",
        "outputId": "32585e82-be81-44b8-eb0a-bd7400d2644f"
      },
      "source": [
        "date_ls=[]\r\n",
        "sqlf=sql5+\" where s1.StaffName_English='{}' and s2.StaffName_English='{}'\"\r\n",
        "sqlls=[]\r\n",
        "# ['Mentor Name', 'MenteeName', 'Start Date', 'End Date', 'Status', 'old date']\r\n",
        "for i in range(len(data)):\r\n",
        "    status=str(data['Status'][i]).strip()\r\n",
        "    date1=str(data['Start Date'][i]).strip()\r\n",
        "    date2=str(data['old date'][i]).strip()\r\n",
        "    n1=str(data['Mentor Name'][i]).strip()\r\n",
        "    n2=str(data['MenteeName'][i]).strip()\r\n",
        "    if(date1!=date2):\r\n",
        "        date_ls.append(i+3)\r\n",
        "    if(status=='未激活'):\r\n",
        "        sql=sqlf.format(n1,n2)\r\n",
        "        sqlls.append(sql)\r\n",
        "print(len(date_ls),len(sqlls))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WzycgRlJFrZ"
      },
      "source": [
        "for sql in sqlls:\r\n",
        "    print(sql)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TObrGrp0JFrb",
        "outputId": "49be4ec7-5b27-4737-ed98-f61dd3bd5e1d"
      },
      "source": [
        "data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mentorname</th>\n",
              "      <th>HR_StaffInfoID</th>\n",
              "      <th>menteename</th>\n",
              "      <th>MenteeID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aaron Guo</td>\n",
              "      <td>72.0</td>\n",
              "      <td>Stella Yang</td>\n",
              "      <td>1347.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aaron Guo</td>\n",
              "      <td>72.0</td>\n",
              "      <td>Arlene Xu</td>\n",
              "      <td>1328.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alice He</td>\n",
              "      <td>42.0</td>\n",
              "      <td>Christina Liao</td>\n",
              "      <td>1301.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carol Cai</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Sifan Huai</td>\n",
              "      <td>1322.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Carol Cai</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Joy Pu</td>\n",
              "      <td>1336.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  mentorname  HR_StaffInfoID      menteename  MenteeID\n",
              "0  Aaron Guo            72.0     Stella Yang    1347.0\n",
              "1  Aaron Guo            72.0       Arlene Xu    1328.0\n",
              "2   Alice He            42.0  Christina Liao    1301.0\n",
              "3  Carol Cai             7.0      Sifan Huai    1322.0\n",
              "4  Carol Cai             7.0          Joy Pu    1336.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYoZmJz7JFrd"
      },
      "source": [
        "for i in range(len(data)):\r\n",
        "    # ['mentorname', 'HR_StaffInfoID', 'menteename', 'MenteeID']\r\n",
        "    name1=str(data['mentorname'][i]).strip()\r\n",
        "    data['HR_StaffInfoID'][i]=pk1=staff_dict[name1]\r\n",
        "    name2=str(data['menteename'][i]).strip()\r\n",
        "    data['MenteeID'][i]=pk2=staff_dict[name2]\r\n",
        "    print(pk1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdec9PlfJFrg",
        "outputId": "25d4c30d-d3b6-4125-fdb7-c594f3566ef5"
      },
      "source": [
        "pk_upd_list=[\r\n",
        "    115,\r\n",
        "    140,\r\n",
        "    101,\r\n",
        "    144,\r\n",
        "    141,\r\n",
        "    77,\r\n",
        "    27,\r\n",
        "    105\r\n",
        "]\r\n",
        "pk_upd_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[115, 140, 101, 144, 141, 77, 27, 105]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzPvPOuKJFrj",
        "outputId": "667ff8e9-e777-46f3-8b31-1d951b248164"
      },
      "source": [
        "sql_upd=\"update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID={}\"\r\n",
        "for pk in pk_upd_list:\r\n",
        "    print(sql_upd.format(pk))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID=115\n",
            "update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID=140\n",
            "update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID=101\n",
            "update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID=144\n",
            "update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID=141\n",
            "update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID=77\n",
            "update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID=27\n",
            "update t_HR_Mentee set CurrentStatus=0 where HR_MenteeID=105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks8c8qTRJFrq",
        "outputId": "dc0f4b02-60ff-49d9-8030-123e2e1afa7e"
      },
      "source": [
        "# ['mentorname', 'HR_StaffInfoID', 'menteename', 'MenteeID', 'old_mentor_name', 'old_mentee_name']\r\n",
        "for i in range(8):\r\n",
        "    name1=str(data['old_mentor_name'][i]).strip()\r\n",
        "    pk1=staff_dict[name1]\r\n",
        "    name2=str(data['old_mentee_name'][i]).strip()\r\n",
        "    pk2=staff_dict[name2]\r\n",
        "    print(pk2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "155\n",
            "72\n",
            "149\n",
            "1244\n",
            "1247\n",
            "56\n",
            "111\n",
            "90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL9x98lyJFrt",
        "outputId": "616a9b94-e3e0-4386-8df0-2f4a230dc88b"
      },
      "source": [
        "sqldata_file='data/pydata_sql.xlsx'\r\n",
        "sqldata=pd.read_excel(io=sqldata_file,header=0)\r\n",
        "print(sqldata.columns.values)\r\n",
        "oldid_ls=[]\r\n",
        "newid_ls=[]\r\n",
        "# len(sqldata['excel_ID'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['excel_ID' 'sql_ID' 'mentor ID' 'Mentor Name' 'Mentor C_Name' 'Mentee ID'\n",
            " 'Mentee Name' 'Mentee C_Name' 'StartDate' 'EndDate' 'CurrentStatus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UedZ03rJFrw",
        "outputId": "73cf8690-4548-4e81-e11c-582e5e1803ad"
      },
      "source": [
        "# sqldata['excel_ID'][79]\r\n",
        "# sqldata['excel_ID'][80]\r\n",
        "for i in range(80):\r\n",
        "    oldid=int(sqldata['excel_ID'][i])\r\n",
        "    newid=sqldata['sql_ID'][i]\r\n",
        "    oldid_ls.append(oldid)\r\n",
        "    newid_ls.append(newid)\r\n",
        "for i in (79,80):\r\n",
        "    oldid_ls.append(int(sqldata['excel_ID'][i]))\r\n",
        "print(len(oldid_ls),len(set(oldid_ls)))\r\n",
        "print(len(newid_ls),len(set(newid_ls)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164 81\n",
            "160 81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fplFCzFhJFry",
        "outputId": "ef49a49b-d0f8-462b-bbd2-c62b91c9c6b6"
      },
      "source": [
        "set(oldid_ls)-set(newid_ls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{74, 96}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8uRGVuIJFrz"
      },
      "source": [
        "# ['mentorname', 'HR_StaffInfoID', 'menteename', 'MenteeID', 'StartDate', 'IsDeleted', 'CreateDate', 'CreateUserID', 'CurrentStatus']\r\n",
        "sql_ins1=\"INSERT INTO table_name ('HR_StaffInfoID','MenteeID','StartDate','IsDeleted','CreateDate','CreateUserID', 'CurrentStatus')VALUES ({0},{1},{2},{3},{4},{5},{6});\"\r\n",
        "for i in range(len(data)):\r\n",
        "    d1=data['HR_StaffInfoID'][i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Dd9-xZKoJFr3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9mXvlLJFr4",
        "outputId": "edc277f7-5781-400e-ff3b-b8765bf96b56"
      },
      "source": [
        "myfile='data/pydata.xlsx'\r\n",
        "data=pd.read_excel(io=myfile,header=0)\r\n",
        "name_list=[]\r\n",
        "for i in range(len(data)):\r\n",
        "    # array(['StaffName_Chinese', 'StaffName_English', 'E_Name', 'AD_Account', 'Code'], dtype=object)\r\n",
        "    name=str(data['StaffName_English'][i])\r\n",
        "    # name=str(data['E_Name'][i])\r\n",
        "    # nl=name.split()\r\n",
        "    # name_list.append(nl)\r\n",
        "    name_a = str(data['AD_Account'][i])\r\n",
        "    name_b=str(data['Code'][i])\r\n",
        "    nl=name_a.split('.')\r\n",
        "    name_list.append(nl)\r\n",
        "    if(name_a!=name_b):\r\n",
        "        print(str(i+2)+\", \"+name_a+\", \"+name_b)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23, Claire.Li, Claire.LI\n",
            "38, M.LU, M.Lu\n",
            "82, Dorothy.Zhu, Dorothy.zhu\n",
            "102, Alice.He, Alice.He001\n",
            "105, Sherry.Yuan, sherry.yuan\n",
            "111, Jiayi.Zhou, JiaYi.Zhou\n",
            "116, Claire.Zhang, Claire.Zhang001\n",
            "118, Simin.Qu, Qu\n",
            "121, July.Lin, July.Lin001\n",
            "135, Jenny.Zhang, Jenny.Zhang001\n",
            "136, Adele.Wu, Adele.Wu001\n",
            "137, Evan.Zhou, Evan.Zhou001\n",
            "138, Carol.Cai, Carol.Cai001\n",
            "139, Faye.Tang, Faye.Tang001\n",
            "140, Matthew.Lu, Matthew.Lu001\n",
            "141, Matthew.Lu, Lu Yun\n",
            "142, SETHI.ASHOK, nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oupBDsagJFr6"
      },
      "source": [
        "for i in range(len(name_list)):\r\n",
        "    nl=name_list[i]\r\n",
        "    # print(':'.join(nl))\r\n",
        "    for item in nl:\r\n",
        "        n=ord(item[0])\r\n",
        "        n1=ord(item[1]) if len(item)>1 else 1\r\n",
        "        n=str(item[1]) if len(item)>1 else '1'\r\n",
        "        # if(not(n>=65 and n<=90) or not(n1>=97 and n1<=122)):\r\n",
        "        if(not(item[0]>='A' and item[0]<='Z') or not(item[1]>='a' and item[1]<='z')):\r\n",
        "        # if(not(n>=65 and n<=90)):\r\n",
        "            print(str(i+2)+\", \"+item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCWSoc_dJFr9"
      },
      "source": [
        "ls1=[]\r\n",
        "ls2=[]\r\n",
        "for i in range(len(data)):\r\n",
        "    # array(['StaffName_Chinese', 'StaffName_English', 'E_Name', 'AD_Account', 'Code'], dtype=object)\r\n",
        "    n1=str(data['StaffName_English'][i])\r\n",
        "    n2=str(data['AD_Account'][i])\r\n",
        "    ls1.append(n2)\r\n",
        "    ls2.append('.'.join(n1.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18xlxZMrJFsA"
      },
      "source": [
        "for i in range(len(ls1)):\r\n",
        "    print(str(i+2)+\", \"+ls1[i]+\", \"+ls2[i])\r\n",
        "    \r\n",
        "    # if(ls1[i]!=ls2[i]):\r\n",
        "    #     print(str(i+2)+\", \"+ls1[i]+\", \"+ls2[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lTnU2WUJFsC",
        "outputId": "447ea29e-2b79-4196-a6dc-e2ffc8869871"
      },
      "source": [
        "file1='data/true.xlsx' # true\r\n",
        "file2='data/test.xlsx' # test\r\n",
        "data1=pd.read_excel(io=file1,header=0)\r\n",
        "data2=pd.read_excel(io=file2,header=0)\r\n",
        "print(data1.columns.values)\r\n",
        "# print(data2.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HR_StaffInfoID' 'StaffName_English' 'AD_Account' 'HR_StaffInfoID.1'\n",
            " 'StaffNumber' 'StaffName_Chinese' 'StaffName_English.1' 'AD_Account.1'\n",
            " 'Sex' 'IDNumber' 'PassPortNumber' 'HKPassport' 'BirthDay' 'HomePhone'\n",
            " 'PhoneNumber' 'PersonalEmail' 'Nationality' 'Nation' 'Birthplace'\n",
            " 'PoliticalStatus' 'PhotoUrl' 'MarriageStatus' 'ResidenceAddress'\n",
            " 'PermanentAddress' 'EmergencyContactPerson' 'EmergencyContactPersonPhone'\n",
            " 'CompanyID' 'DepartmentID' 'PositionID' 'LineManager' 'ExtensionNumber'\n",
            " 'CompanyEmail' 'StaffStatus' 'StaffType' 'EntryDate' 'LeaveDate'\n",
            " 'VacationDays' 'UpdateDate' 'CreateDate' 'IsDeleted' 'UpdateUserId'\n",
            " 'CreatedUserId' 'IsTeamLeader' 'IsHaveChild' 'MappingERPID'\n",
            " 'IDNumberExpireDate' 'PassportNumberExpireDate' 'HKPassportExpireDate'\n",
            " 'Hukou' 'IsAuthorized']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNGisD6EJFsE",
        "outputId": "98d8c87d-4f75-4ded-cbaf-cdfd0a9b9229"
      },
      "source": [
        "for i in range(324):\r\n",
        "    name1=str(data1['StaffName_English'][i]).strip()\r\n",
        "    name2=str(data2['StaffName_English'][i]).strip()\r\n",
        "    id1=str(data1['HR_StaffInfoID'][i])\r\n",
        "    id2=str(data2['HR_StaffInfoID'][i])\r\n",
        "    if(name1!=name2):\r\n",
        "        print(\"true: \"+id1+':'+name1+\"\\ttest \"+id2+':'+name2)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "true: 201:Gina Fei\ttest 201:Yulin Fei\n",
            "true: 1255:Chelsie Chen\ttest 1255:Xi Chen1\n",
            "true: 1272:Jane Zhang\ttest 1272:Han Zhang\n",
            "true: 1275:Rebecca Zhou\ttest 1275:Rui Zhou\n",
            "true: 1277:Olivia Chang\ttest 1277:Chuting Chang\n",
            "true: 1291:Tina Du\ttest 1291:Zeyuan Du\n",
            "true: 1307:Mieko Feng\ttest 1307:Jiaye Feng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPbM5ddkJFsH"
      },
      "source": [
        "mystr=\"update t_HR_StaffInfo set AD_Account='{ad}' where StaffName_English='{name}'\"\r\n",
        "for i in range(len(data1)):\r\n",
        "    ad=str(data1['AD_Account'][i]).strip()\r\n",
        "    name=str(data1['StaffName_English'][i]).strip()\r\n",
        "    print(mystr.format(ad=ad,name=name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCe3tqoqJFsO",
        "outputId": "f8553708-0a1c-4429-c6a5-2e2c494b3d21"
      },
      "source": [
        "adfile='data/nullad.xlsx'\r\n",
        "addata=pd.read_excel(io=adfile,header=0)\r\n",
        "addata.columns.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HR_StaffInfoID', 'StaffName_English', 'AD_Account',\n",
              "       'HR_StaffInfoID.1', 'StaffNumber', 'StaffName_Chinese',\n",
              "       'StaffName_English.1', 'AD_Account.1', 'Sex', 'IDNumber',\n",
              "       'PassPortNumber', 'HKPassport', 'BirthDay', 'HomePhone',\n",
              "       'PhoneNumber', 'PersonalEmail', 'Nationality', 'Nation',\n",
              "       'Birthplace', 'PoliticalStatus', 'PhotoUrl', 'MarriageStatus',\n",
              "       'ResidenceAddress', 'PermanentAddress', 'EmergencyContactPerson',\n",
              "       'EmergencyContactPersonPhone', 'CompanyID', 'DepartmentID',\n",
              "       'PositionID', 'LineManager', 'ExtensionNumber', 'CompanyEmail',\n",
              "       'StaffStatus', 'StaffType', 'EntryDate', 'LeaveDate',\n",
              "       'VacationDays', 'UpdateDate', 'CreateDate', 'IsDeleted',\n",
              "       'UpdateUserId', 'CreatedUserId', 'IsTeamLeader', 'IsHaveChild',\n",
              "       'MappingERPID', 'IDNumberExpireDate', 'PassportNumberExpireDate',\n",
              "       'HKPassportExpireDate', 'Hukou', 'IsAuthorized',\n",
              "       'IsRequireUpdate_Entry', 'IsRequireUpdate_Leave'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_TRZysKJFsR"
      },
      "source": [
        "mystr=\"update t_HR_StaffInfo set AD_Account='{ad}' where StaffName_English='{name}'\"\r\n",
        "for i in range(len(addata)):\r\n",
        "    name=str(addata['StaffName_English'][i]).strip()\r\n",
        "    ad=name.replace(' ','.',2)\r\n",
        "    print(mystr.format(ad=ad,name=name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT8-yosQJFsT",
        "outputId": "44ecec4e-30ca-4014-f148-1dc0ed5f144b"
      },
      "source": [
        "file1='data/standard.xlsx' # true\r\n",
        "file2='data/test.xlsx' # test\r\n",
        "data1=pd.read_excel(io=file1,header=0)\r\n",
        "data2=pd.read_excel(io=file2,header=0)\r\n",
        "print(data1.columns.values)\r\n",
        "print(data2.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No.' '直线号码段' '分机号' 'Name' 'Name.1' '备注']\n",
            "['No.' 'Name-E' 'Name-C' '分机号' '状态']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuyKScMUJFsV"
      },
      "source": [
        "for i in range(len(data1)):\r\n",
        "    name1=str(data1['Name'][i])\r\n",
        "    standard=str(data1['分机号'][i])\r\n",
        "    for j in range(len(data2)):\r\n",
        "        if(name1==data2['Name-E'][j]):\r\n",
        "            test=str(data2['分机号'][j])\r\n",
        "            # if(standard!=test):\r\n",
        "            #     print(standard+\"\\t\"+test)\r\n",
        "            print(standard+\"\\t\"+test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcbVLqrTJFsW",
        "outputId": "282068ac-9acd-4592-b665-6ffa9922ec41"
      },
      "source": [
        "taskfile='data/task.xlsx'\r\n",
        "taskdata=pd.read_excel(io=taskfile,header=0)\r\n",
        "print(taskdata.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No.' 'Name-E' 'Name-C' 'Name-E.1' '打印机端口号' '状态']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psTgUR5lJFsZ",
        "outputId": "330fb49f-ae87-4f41-c102-2482648e6b25"
      },
      "source": [
        "for i in range(len(taskdata)):\r\n",
        "    name1=str(taskdata['Name-E'][i])\r\n",
        "    name2=str(taskdata['Name-E.1'][i])\r\n",
        "    if(name1!=name2):\r\n",
        "        print(str(i)+\"\\t\"+name1+\"\\t\"+name2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\tIris Xu\tnan\n",
            "40\tIssac Ku\tIris Xu\n",
            "41\tJane Li\tIssac Ku\n",
            "42\tJane Zhang\tJane Li\n",
            "43\tJanice Wang\tJane Zhang\n",
            "44\tJason Pan\tJanice Wang\n",
            "45\tJenny Zhang\tJason Pan\n",
            "46\tJerry Jiao\tJenny Zhang\n",
            "47\tJessie Sun\tJerry Jiao\n",
            "48\tJessy Liu\tJessie Sun\n",
            "49\tJiajia Hao\tJessy Liu\n",
            "50\tJiayi Zhou\tJiajia Hao\n",
            "51\tJoy Pu\tJiayi Zhou\n",
            "52\tJuly Lin\tJoy Pu\n",
            "53\tKang Su\tJuly Lin\n",
            "54\tKaren Duan\tKang Su\n",
            "55\tKaren Liu\tKaren Duan\n",
            "56\tKaya Zhang\tKaren Liu\n",
            "57\tKelly Chen\tKaya Zhang\n",
            "58\tKevin Cai\tKelly Chen\n",
            "59\tLace Zhang\tKevin Cai\n",
            "60\tLeo Li\tLace Zhang\n",
            "61\tLeon Duan\tLeo Li\n",
            "62\tLeslie Wang\tLeon Duan\n",
            "63\tLilith Hua\tLeslie Wang\n",
            "64\tLily Chen\tLilith Hua\n",
            "65\tLily Wang\tLily Chen\n",
            "66\tLynn Chen\tLily Wang\n",
            "67\tLynn Zheng\tLynn Chen\n",
            "68\tM LU\tLynn Zheng\n",
            "69\tMatthew Lu\tM LU\n",
            "70\tMavis Tong\tMatthew Lu\n",
            "71\tMia Wei\tMavis Tong\n",
            "72\tMieko Feng\tMia Wei\n",
            "73\tMira Ma\tMieko Feng\n",
            "74\tMonica Yang\tMira Ma\n",
            "75\tNaomi Chen\tMonica Yang\n",
            "76\tNeal Teng\tNaomi Chen\n",
            "77\tNeo Wu\tNeal Teng\n",
            "78\tNerissa Sun\tNeo Wu\n",
            "79\tNora Xu \tNerissa Sun\n",
            "80\tOlivia Chang\tNora Xu \n",
            "81\tOlivia Ma\tOlivia Chang\n",
            "82\tOorain Ju\tOlivia Ma\n",
            "83\tPatrick Li\tOorain Ju\n",
            "84\tPaul Zhou\tPatrick Li\n",
            "85\tPencil Chen\tPaul Zhou\n",
            "86\tPerry Bian\tPencil Chen\n",
            "87\tRachel Ding\tPerry Bian\n",
            "88\tRebecca Zhou\tRachel Ding\n",
            "89\tRobin Lin\tRebecca Zhou\n",
            "90\tRose Feng\tRobin Lin\n",
            "91\tSabrina Zhu\tRose Feng\n",
            "92\tSally Li\tSabrina Zhu\n",
            "93\tSerena Zhang\tSally Li\n",
            "94\tSerlin Qian\tSerena Zhang\n",
            "95\tSETHI ASHOK\tSerlin Qian\n",
            "96\tShanshan Ye\tSETHI ASHOK\n",
            "97\tSharon Shen\tShanshan Ye\n",
            "98\tShawn Song\tSharon Shen\n",
            "99\tShelly Wei\tShawn Song\n",
            "100\tShen Jing\tShelly Wei\n",
            "101\tSherry Yuan\tShen Jing\n",
            "102\tSifan Huai\tSherry Yuan\n",
            "103\tSimin Qu\tShoujun Zhang\n",
            "104\tSkye Sun\tSifan Huai\n",
            "105\tSophia Zhuo\tSimin Qu\n",
            "106\tStella Wang\tSkye Sun\n",
            "107\tStella Yang\tSophia Zhuo\n",
            "108\tSteven Shuai\tStella Wang\n",
            "109\tThea Cui\tStella Yang\n",
            "110\tThea Zhang\tSteven Shuai\n",
            "111\tTheresa Ye\tThea Cui\n",
            "112\tTina Du\tThea Zhang\n",
            "113\tTong Wang\tTheresa Ye\n",
            "114\tTracy Kong\tTina Du\n",
            "115\tVera Li\tTong Wang\n",
            "116\tVera Xu\tTracy Kong\n",
            "117\tVera Zhang\tVera Li\n",
            "118\tViona Li\tVera Xu\n",
            "119\tVivi Wu\tVera Zhang\n",
            "120\tWei Liu\tViona Li\n",
            "121\tWendy Zang\tVivi Wu\n",
            "122\tXi Wen\tWei Liu\n",
            "123\tXue Wu\tWendy Zang\n",
            "124\tYang Yang\tXi Wen\n",
            "125\tYuki Wu\tXue Wu\n",
            "126\tZemin Fan\tYang Yang\n",
            "127\tZenki Zhang\tYuki Wu\n",
            "128\tZora Yu\tZemin Fan\n",
            "129\tSophie Chai\tZenki Zhang\n",
            "130\tnan\tZora Yu\n",
            "131\tnan\t阿姨\n",
            "132\tnan\tSophie Chai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxQWFQEuJFse",
        "outputId": "565d9815-ae37-4415-bd6f-3c5391ac2db2"
      },
      "source": [
        "i=11\r\n",
        "\r\n",
        "import calendar\r\n",
        "\r\n",
        "\r\n",
        "cal=calendar.Calendar()\r\n",
        "n=0\r\n",
        "dates=cal.itermonthdates(2020,i)\r\n",
        "for d in dates:\r\n",
        "    if(n%7==0):\r\n",
        "        print(\"\\n\\n\\n\\n\\n\")\r\n",
        "    mystr=d.strftime('%m月 %d日')\r\n",
        "    print(mystr,end=\"\\t\\t\")\r\n",
        "    n=n+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "10月 26日\t\t10月 27日\t\t10月 28日\t\t10月 29日\t\t10月 30日\t\t10月 31日\t\t11月 01日\t\t\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11月 02日\t\t11月 03日\t\t11月 04日\t\t11月 05日\t\t11月 06日\t\t11月 07日\t\t11月 08日\t\t\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11月 09日\t\t11月 10日\t\t11月 11日\t\t11月 12日\t\t11月 13日\t\t11月 14日\t\t11月 15日\t\t\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11月 16日\t\t11月 17日\t\t11月 18日\t\t11月 19日\t\t11月 20日\t\t11月 21日\t\t11月 22日\t\t\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11月 23日\t\t11月 24日\t\t11月 25日\t\t11月 26日\t\t11月 27日\t\t11月 28日\t\t11月 29日\t\t\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11月 30日\t\t12月 01日\t\t12月 02日\t\t12月 03日\t\t12月 04日\t\t12月 05日\t\t12月 06日\t\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geEhUXBRJFsh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-x6yBiMJFsj"
      },
      "source": [
        "from xml.dom.minidom import parse\r\n",
        "# from urllib.request import urlopen\r\n",
        "# from xml.etree.ElementTree import parse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlghFwx3JFsl"
      },
      "source": [
        "dom=parse('data/IPOFFICESD_Users.xml')\r\n",
        "data=dom.documentElement\r\n",
        "users=data.getElementsByTagName('tns:user')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCKgfBeyJFsn",
        "outputId": "1b85df7b-7234-4308-a802-5c515ddff943"
      },
      "source": [
        "from pandas import Series,DataFrame\r\n",
        "import pandas as pd\r\n",
        "!pip install openpyxl\r\n",
        "import openpyxl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
            "Collecting openpyxl\n",
            "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/5c/90/61f83be1c335a9b69fa773784a785d9de95c7561d1661918796fd1cba3d2/openpyxl-3.0.5-py2.py3-none-any.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 4.6MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting jdcal (from openpyxl)\n",
            "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/f0/da/572cbc0bc582390480bbd7c4e93d14dc46079778ed915b505dc494b37c57/jdcal-1.4.1-py2.py3-none-any.whl\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/22/28/a99c42aea746e18382ad9fb36f64c1c1f04216f41797f2f0fa567da11388/et_xmlfile-1.0.1.tar.gz\n",
            "Building wheels for collected packages: et-xmlfile\n",
            "  Building wheel for et-xmlfile (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for et-xmlfile: filename=et_xmlfile-1.0.1-cp37-none-any.whl size=8917 sha256=8e87ea7f83d6e9ff744c00d87622bd2bff725798bbc025d1bc4aa056ca487896\n",
            "  Stored in directory: /home/aistudio/.cache/pip/wheels/22/08/69/f546610376ad227cb3f48c8c39dec786990fdbc961dc69ff9d\n",
            "Successfully built et-xmlfile\n",
            "Installing collected packages: jdcal, et-xmlfile, openpyxl\n",
            "Successfully installed et-xmlfile-1.0.1 jdcal-1.4.1 openpyxl-3.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp77fi9RJFsp"
      },
      "source": [
        "df=pd.DataFrame(columns=[\"E_Name\",\"C_Name\",\"extension\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6GrajoUJFsq"
      },
      "source": [
        "for user in users:\r\n",
        "    loginname=user.getElementsByTagName('loginName')[0].childNodes[0].nodeValue.strip(\"@user\").split(' ')\r\n",
        "    extension=user.getElementsByTagName('csm:extension')[0].childNodes[0].nodeValue\r\n",
        "    ename=loginname[0]\r\n",
        "    cname=\"\"\r\n",
        "    if(len(loginname)>2):\r\n",
        "        ename=loginname[0]+\" \"+loginname[1]\r\n",
        "        cname=loginname[-1]\r\n",
        "    userdict={'E_Name':ename,'C_Name':cname,'extension':extension}\r\n",
        "    df=df.append(userdict,ignore_index=True)\r\n",
        "    # print(userdict)\r\n",
        "\r\n",
        "datalength=len(users)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaYYpTG9JFss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXZttlS7JFsu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlMzwFKrJFsv"
      },
      "source": [
        "import datetime\r\n",
        "now=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n",
        "filename=\"AVAYA分机号\"+str(datalength)+\"_\"+now+\".xlsx\"\r\n",
        "\r\n",
        "df.to_excel(\"work/\"+filename)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEgGLHruJFsx",
        "outputId": "4c5d0282-7c83-4b44-df17-577c3c0e7b28"
      },
      "source": [
        "import pandas as pd\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "! pip install xlrd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
            "Collecting xlrd\n",
            "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.1MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: xlrd\n",
            "Successfully installed xlrd-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihJpSsVSJFsy",
        "outputId": "e644f2c7-d6c8-481e-d6db-e4fa343bf289"
      },
      "source": [
        "cardfile='data/card0818.xlsx'\r\n",
        "cardinfo=pd.read_excel(io=cardfile,header=0)\r\n",
        "extenfile='data/143_20200918_133203.xlsx'\r\n",
        "extdata=pd.read_excel(io=extenfile,header=0)\r\n",
        "\r\n",
        "print(len(cardinfo))\r\n",
        "print(cardinfo.columns.values)\r\n",
        "print(len(extdata))\r\n",
        "print(extdata.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131\n",
            "['序号' '部门' '中文名' '英文名' '中文职位' '英文职位' '总机' '分机号' '手机' '邮箱' '名片份数']\n",
            "143\n",
            "['E_Name' 'C_Name' 'extension']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tLePSmlJFs0",
        "outputId": "8815996b-d0d3-4e9b-da3a-99728df8a73a"
      },
      "source": [
        "for i in range(len(cardinfo)):\r\n",
        "    card_ename=str(cardinfo['英文名'][i]).strip()\r\n",
        "    card_ext=int(cardinfo['分机号'][i])\r\n",
        "    for j in range(len(extdata)):\r\n",
        "        ext_ename=str(extdata['E_Name'][j]).strip()\r\n",
        "        ext_extnum=int(extdata['extension'][j])\r\n",
        "        # if((card_ename==ext_ename) and str(card_ext)!=str(ext_extnum)):\r\n",
        "            # print(card_ename+'\\tcard: '+str(card_ext)+'\\tsystem: '+str(ext_extnum))\r\n",
        "        if((card_ext==ext_extnum) and (card_ename!=ext_ename)):\r\n",
        "            print(str(card_ext)+',\\t'+str(card_ename)+',\\t'+ext_ename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8116,\tFrances Zhang,\tFrances Z\n",
            "8077,\tSETHIASHOK,\tSETHI ASHOK\n",
            "8152,\tSerena Zhang,\tSerena Z\n",
            "8141,\tGina Fei,\tYulin Fei\n",
            "8122,\tFrancis Huang,\tFrancis H\n",
            "8136,\tOlivia Chang,\tChuting C\n",
            "8135,\tSteven Shuai,\tSteven\n",
            "8121,\tGabrielle Guan,\tGabrielle G\n",
            "8137,\tChristina Liao,\tChristina L\n",
            "8049,\tClaire Zhang,\tClaire Z\n",
            "8133,\tSophie Chai,\tSophieChai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUl5NtcbJFs2",
        "outputId": "a77ac9fd-1924-4ea6-d7e9-91c18ad66ef2"
      },
      "source": [
        "set_cardext=set(cardinfo['分机号'])\r\n",
        "set_syext=set(extdata['extension'])\r\n",
        "subSet=set_syext-set_cardext\r\n",
        "print(subSet)\r\n",
        "for j in range(len(extdata)):\r\n",
        "    ext_ename=str(extdata['E_Name'][j]).strip()\r\n",
        "    ext_extnum=int(extdata['extension'][j])\r\n",
        "    if(ext_extnum in subSet):\r\n",
        "        print(ext_ename+'\\t'+str(ext_extnum))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{8000, 8103, 8072, 8105, 8074, 8108, 8109, 8111, 8112, 8113, 8115, 8053, 8091, 8092}\n",
            "Newton\t8053\n",
            "Einstein\t8072\n",
            "Galileo\t8074\n",
            "Franklin\t8091\n",
            "Da\t8092\n",
            "Hugo\t8103\n",
            "Bacon\t8105\n",
            "Mozart\t8108\n",
            "Goeth\t8109\n",
            "Haydn\t8112\n",
            "Copernic\t8111\n",
            "Switchboard\t8000\n",
            "Jane\t8113\n",
            "Joe Zhu\t8115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7zDZ7L9JFs5",
        "outputId": "abfea379-d856-4f9f-a9a0-30e6fcce9d4b"
      },
      "source": [
        "myfile='data/分机号_20200918_170104.xlsx'\r\n",
        "mydata=pd.read_excel(io=myfile,header=0)\r\n",
        "\r\n",
        "print(len(mydata))\r\n",
        "print(mydata.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159\n",
            "['序号' '连续' 'loginName' 'C_Name' 'extension' '分机号' '中文名' '英文名']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p4Q-4DjJFs7",
        "outputId": "35ea1c31-addc-441b-ab06-b467f2fde89d"
      },
      "source": [
        "for i in range(len(mydata)):\r\n",
        "    sy_name=str(mydata['C_Name'][i]).strip()\r\n",
        "    card_name=str(mydata['中文名'][i]).strip()\r\n",
        "    sy_ext=str(mydata['extension'][i]).strip()\r\n",
        "    card_ext=str(mydata['分机号'][i]).strip()\r\n",
        "    if((sy_name!=card_name) or (sy_ext!=card_ext)):\r\n",
        "        output=\"{0},{1},{2},{3}\".format(sy_name,card_name,sy_ext,card_ext)\r\n",
        "        print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nan,nan,8000.0,nan\n",
            "金振末,金振未,8026.0,8026.0\n",
            "nan,王卉,nan,8031.0\n",
            "卞鹏瑞,卞鹏睿,8036.0,8036.0\n",
            "nan,杜泽元,nan,8038.0\n",
            "nan,nan,8053.0,nan\n",
            "许沺,徐沺,8065.0,8065.0\n",
            "封佳钰,封加烨,8067.0,8067.0\n",
            "nan,nan,8072.0,nan\n",
            "nan,nan,8074.0,nan\n",
            "nan,nan,8091.0,nan\n",
            "nan,nan,8092.0,nan\n",
            "nan,nan,8103.0,nan\n",
            "nan,nan,8105.0,nan\n",
            "nan,nan,8108.0,nan\n",
            "nan,nan,8109.0,nan\n",
            "nan,nan,8111.0,nan\n",
            "nan,nan,8112.0,nan\n",
            "张吴江,nan,8113.0,nan\n",
            "滕赟,滕贇,8114.0,8114.0\n",
            "朱萍,nan,8115.0,nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ztmayOlJFs8",
        "outputId": "6ab2e6f4-feed-4eea-8298-468ed548240d"
      },
      "source": [
        "from pandas import Series,DataFrame\r\n",
        "import pandas as pd\r\n",
        "!pip install openpyxl\r\n",
        "import openpyxl\r\n",
        "!pip install xlrd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
            "Requirement already satisfied: openpyxl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (3.0.5)\n",
            "Requirement already satisfied: jdcal in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl) (1.4.1)\n",
            "Requirement already satisfied: et-xmlfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl) (1.0.1)\n",
            "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
            "Requirement already satisfied: xlrd in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBnjrE2vJFs-"
      },
      "source": [
        "df=pd.DataFrame(columns=[\"连续\",\"分机号\",\"英文名\",\"中文名\",\"loginName\",\"备注\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeo9zjw5JFs_",
        "outputId": "4b685208-731c-4c3f-bba2-812b0a7d40c6"
      },
      "source": [
        "cardfile='data/card0818.xlsx'\r\n",
        "cardinfo=pd.read_excel(io=cardfile,header=0)\r\n",
        "extenfile='data/143_20200919_004133.xlsx'\r\n",
        "extdata=pd.read_excel(io=extenfile,header=0)\r\n",
        "\r\n",
        "print(len(cardinfo))\r\n",
        "print(cardinfo.columns.values)\r\n",
        "print(len(extdata))\r\n",
        "print(extdata.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131\n",
            "['序号' '部门' '中文名' '英文名' '中文职位' '英文职位' '总机' '分机号' '手机' '邮箱' '名片份数']\n",
            "143\n",
            "['loginName' 'E_Name' 'C_Name' 'extension']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJk5Q13EJFtB"
      },
      "source": [
        "remark=ename=cname=loginName=extension=\"\"\r\n",
        "    # 1. 根据ext匹配data里的数据\r\n",
        "    # 2. 填入ename cname loginname \r\n",
        "    # 3. loginname: 'Switchboard'->前台\r\n",
        "    #               ['Hugo','Bacon','Mozart','Goeth','Copernic','Haydn']->电话间\r\n",
        "    #               ['Newton','Einstein','Galileo','Franklin','Da Vinci']->会议室\r\n",
        "ls_r1=['Newton','Einstein','Galileo','Franklin','Da Vinci']\r\n",
        "ls_r2=['Hugo','Bacon','Mozart','Goeth','Copernic','Haydn']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPfRQDUeJFtD"
      },
      "source": [
        "for index in range(200):\r\n",
        "    indexEXT=8000+index\r\n",
        "    for i in range(len(extdata)):\r\n",
        "        sy_ext=int(extdata['extension'][i])\r\n",
        "        if(sy_ext==indexEXT):\r\n",
        "            loginName=str(extdata['loginName'][i]).strip()\r\n",
        "            if loginName in ls_r1:\r\n",
        "                remark=\"会议室\"\r\n",
        "            elif loginName in ls_r2:\r\n",
        "                remark=\"电话间\"\r\n",
        "            else:\r\n",
        "                remark=\"前台\" if(loginName==\"Switchboard\") else ''\r\n",
        "            break\r\n",
        "    for j in range(len(cardinfo)):\r\n",
        "        card_ext=int(cardinfo['分机号'][j])\r\n",
        "        if(card_ext==indexEXT):\r\n",
        "            ename=str(cardinfo['英文名'][j]).strip()\r\n",
        "            cname=str(cardinfo['中文名'][j]).strip()\r\n",
        "            break\r\n",
        "    if(sy_ext==card_ext):\r\n",
        "        extension=sy_ext\r\n",
        "    if(loginName==''):\r\n",
        "        remark=\"留空\"\r\n",
        "    userdict={'连续':indexEXT,'分机号':extension,'英文名':ename,'中文名':cname,'loginName':loginName,'备注':remark}\r\n",
        "    df=df.append(userdict,ignore_index=True)\r\n",
        "    remark=ename=cname=loginName=extension=\"\"\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRdabU7JJFtG"
      },
      "source": [
        "import datetime\r\n",
        "now=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n",
        "filename=\"分机号_\"+now+\".xlsx\"\r\n",
        "\r\n",
        "df.to_excel(\"work/\"+filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ndCvVn8JFtH",
        "outputId": "5980805c-5e27-416e-9cd5-abf7d4591029"
      },
      "source": [
        "from sympy import *\r\n",
        "\r\n",
        "a3=Symbol('a3')\r\n",
        "a4=Symbol('a4')\r\n",
        "a5=Symbol('a5')\r\n",
        "\r\n",
        "val=solve([a3+a4+a5-1,a3*50+a4*250+a5*2000-256],[a3,a4,a5])\r\n",
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{a4: 103/100 - 39*a5/4, a3: 35*a5/4 - 3/100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIu69i2FJFtK"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "ls=[]\r\n",
        "a5=0.001\r\n",
        "while(a5<0.01):\r\n",
        "    a4=103/100 - 39*a5/4\r\n",
        "    a3=35*a5/4 - 3/100\r\n",
        "    ls.append([a3,a4,a5])\r\n",
        "    a5+=0.001\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_7SwsOQJFtM"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwMpVEt9JFtP"
      },
      "source": [
        "dom=parse('data/convertSwf_0_5079.xml')\r\n",
        "data=dom.documentElement\r\n",
        "sn_dom=data.getElementsByTagName('sn')\r\n",
        "status_dom=data.getElementsByTagName('status')\r\n",
        "fileID_dom=data.getElementsByTagName('fileID')\r\n",
        "title_dom=data.getElementsByTagName('title')\r\n",
        "fileName_dom=data.getElementsByTagName('fileName')\r\n",
        "fileType_dom=data.getElementsByTagName('fileType')\r\n",
        "createTime_dom=data.getElementsByTagName('createTime')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7tAqwArJFtR"
      },
      "source": [
        "import pandas as pd\r\n",
        "df=pd.DataFrame(columns=[\"sn\",\"status\",\"fileID\",\"title\",\"fileName\",\"fileType\",\"createTime\"])\r\n",
        "for i in range(len(sn_dom)):\r\n",
        "    v1=sn_dom[i].childNodes[0].nodeValue\r\n",
        "    v2=status_dom[i].childNodes[0].nodeValue\r\n",
        "    v3=title_dom[i].childNodes[0].nodeValue\r\n",
        "    v4=fileID_dom[i].childNodes[0].nodeValue\r\n",
        "    v5=v6=\"\"\r\n",
        "    if(i not in (3621,3633,3699,3718,3761,3837,3997,4081,4102,4165)):\r\n",
        "        v5=fileType_dom[i].childNodes[0].nodeValue\r\n",
        "    if(i!=204):\r\n",
        "        v6=fileName_dom[i].childNodes[0].nodeValue\r\n",
        "    v7=createTime_dom[i].childNodes[0].nodeValue\r\n",
        "    mydict={'sn':v1,'status':v2,'fileID':v4,'title':v3,'fileName':v6,'fileType':v5,'createTime':v7}\r\n",
        "    df=df.append(mydict,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYvkfz2mJFtT"
      },
      "source": [
        "df.to_excel(\"export.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhQH0cJGJFtY",
        "outputId": "6759a472-033c-4e46-9acd-60d2cadadae7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sn</th>\n",
              "      <th>status</th>\n",
              "      <th>fileID</th>\n",
              "      <th>title</th>\n",
              "      <th>fileName</th>\n",
              "      <th>fileType</th>\n",
              "      <th>createTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Success</td>\n",
              "      <td>30168</td>\n",
              "      <td>新型冠状病毒影响之下的营销趋势预判与洞察-蓝标-20200220.pdf</td>\n",
              "      <td>新型冠状病毒影响之下的营销趋势预判与洞察-蓝标-20200220</td>\n",
              "      <td>pdf</td>\n",
              "      <td>2020/10/16 23:53:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Success</td>\n",
              "      <td>30169</td>\n",
              "      <td>见实科技-公域私域新组合.pdf</td>\n",
              "      <td>见实科技-公域私域新组合</td>\n",
              "      <td>pdf</td>\n",
              "      <td>2020/10/16 23:54:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Success</td>\n",
              "      <td>30170</td>\n",
              "      <td>阿里VS京东VS拼多多：三大平台之对比分析-分级、竞争、进化-2020.5.pdf</td>\n",
              "      <td>阿里VS京东VS拼多多：三大平台之对比分析-分级、竞争、进化-20205</td>\n",
              "      <td>5</td>\n",
              "      <td>2020/10/16 23:54:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Success</td>\n",
              "      <td>30171</td>\n",
              "      <td>1_苏世民我的经验与教训.pdf</td>\n",
              "      <td>1_苏世民我的经验与教训</td>\n",
              "      <td>pdf</td>\n",
              "      <td>2020/10/16 23:56:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Success</td>\n",
              "      <td>30172</td>\n",
              "      <td>BCG-假说驱动管理.pdf</td>\n",
              "      <td>BCG-假说驱动管理</td>\n",
              "      <td>pdf</td>\n",
              "      <td>2020/10/16 23:58:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sn   status fileID                                      title  \\\n",
              "0  0  Success  30168       新型冠状病毒影响之下的营销趋势预判与洞察-蓝标-20200220.pdf   \n",
              "1  1  Success  30169                           见实科技-公域私域新组合.pdf   \n",
              "2  2  Success  30170  阿里VS京东VS拼多多：三大平台之对比分析-分级、竞争、进化-2020.5.pdf   \n",
              "3  3  Success  30171                           1_苏世民我的经验与教训.pdf   \n",
              "4  4  Success  30172                             BCG-假说驱动管理.pdf   \n",
              "\n",
              "                               fileName fileType           createTime  \n",
              "0      新型冠状病毒影响之下的营销趋势预判与洞察-蓝标-20200220      pdf  2020/10/16 23:53:38  \n",
              "1                          见实科技-公域私域新组合      pdf  2020/10/16 23:54:33  \n",
              "2  阿里VS京东VS拼多多：三大平台之对比分析-分级、竞争、进化-20205        5  2020/10/16 23:54:52  \n",
              "3                          1_苏世民我的经验与教训      pdf  2020/10/16 23:56:53  \n",
              "4                            BCG-假说驱动管理      pdf  2020/10/16 23:58:05  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZqRwZ3iJFta"
      },
      "source": [
        "cs=cf=0\r\n",
        "for c in df.status:\r\n",
        "    cs+=(1 if c=='Success' else 0)\r\n",
        "    cf+=(1 if c=='Fail' else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61s24LeMJFtd",
        "outputId": "58e6ac5e-6b55-4659-b05c-ccf5fceb0d7b"
      },
      "source": [
        "print(cs,cf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "817 4263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ThST7qyJFtf"
      },
      "source": [
        "dom=parse('data/FeedBack_1104_2238.xml')\r\n",
        "data=dom.documentElement\r\n",
        "fbs=data.getElementsByTagName('FeedBack')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYFU-bYzJFtg"
      },
      "source": [
        "import pandas as pd\r\n",
        "df=pd.DataFrame(columns=[\"sn\",\"status\",\"fileID\",\"title\",\"fileName\",\"fileType\",\"createTime\"]) \r\n",
        "ls_file_not_exist=[]\r\n",
        "ls_copyFail=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrva1kdRJFth"
      },
      "source": [
        "for fb in fbs:\r\n",
        "    sn=fb.getElementsByTagName('sn')[0].childNodes[0].nodeValue\r\n",
        "    status=fb.getElementsByTagName('status')[0].childNodes[0].nodeValue\r\n",
        "    fileID=fb.getElementsByTagName('fileID')[0].childNodes[0].nodeValue\r\n",
        "    title=fb.getElementsByTagName('title')[0].childNodes[0].nodeValue\r\n",
        "    fileName=fb.getElementsByTagName('fileName')[0].childNodes[0].nodeValue\r\n",
        "    # print(len(fb.getElementsByTagName('fileType')[0].childNodes))\r\n",
        "    if(len(fb.getElementsByTagName('fileType')[0].childNodes)>0):\r\n",
        "        fileType=fb.getElementsByTagName('fileType')[0].childNodes[0].nodeValue\r\n",
        "    else:\r\n",
        "        fileType=title.split('.')[-1]\r\n",
        "    createTime=fb.getElementsByTagName('createTime')[0].childNodes[0].nodeValue\r\n",
        "    if(\"exist\" in status):\r\n",
        "        ls_file_not_exist.append(fileID)\r\n",
        "    if(\"Fail\" in status and fileType in [\"doc\",\"docx\",\"xls\",\"xlsx\",\"ppt\",\"pptx\",\"pdf\"]):\r\n",
        "        ls_copyFail.append(fileID)\r\n",
        "    fbdict={\"sn\":sn,\"status\":status,\"fileID\":fileID,\"title\":title,\"fileName\":fileName,\"fileType\":fileType,\"createTime\":createTime}\r\n",
        "    df=df.append(fbdict,ignore_index=True)\r\n",
        "    # print(userdict)\r\n",
        "    # print(sn)\r\n",
        "\r\n",
        "datalength=len(fbs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNWv8n1-JFti"
      },
      "source": [
        "df.to_excel(\"feedBack_pms.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr-HVSRlJFtk"
      },
      "source": [
        "# work/output.txt\r\n",
        "f_op = open(\"work/output.txt\", 'w+',encoding=\"utf-8\")\r\n",
        "print(ls_copyFail,file=f_op)\r\n",
        "f_op.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyThXLIBJFtl",
        "outputId": "9ee075bb-e8cf-4f44-9eb1-f02d0f6febcb"
      },
      "source": [
        "len(ls_copyFail)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUwh52oLJFtn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJfrGV4PJFto"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPvKhVKZJFtp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1So_-zaJFtt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daNyYWmbJFtu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}